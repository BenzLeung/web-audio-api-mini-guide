{"./":{"url":"./","title":"关于本教程","keywords":"","body":"关于本教程 Web Audio API 好好玩，我一接触到这玩意就迷上了它。 然而，网上暂时还没有一篇能让我觉得比较满意的入门教程，于是我想自己写一个。 第一次写教程，可能写得不太好，望勿见笑。 欢迎访问： 我的Github：https://github.com/benzleung/ 我的Blog：http://www.jianshu.com/p/8f8092a07487 "},"chapter1.html":{"url":"chapter1.html","title":"1. 它能做什么？","keywords":"","body":"1. 它能做什么？ 1.用作游戏的音效，可以方便地混音，同时地混着播放两个或以上音轨 2.使用内置的均衡器（BiquadFilter），可方便地定制音乐效果 3.使用内置的声源模型（Panner），创造身临其境的3D音效 4.使用内置的音频分析器（Analyser），绘制超动感的可视化效果 5.使用内置的振荡器（Oscillator），无须加载音频文件直接生成声音,网页版电子琴不成问题！还能自己做DJ！ 6.使用内置的媒体流（MediaStream），直接从麦克风录制音频并即时处理,网页版KTV也不成问题！（目前移动端似乎暂未支持） 浏览器兼容性 最新的浏览器支持情况可参阅：http://caniuse.com/#feat=audio-api 对录音功能（MediaStream）的支持情况可参阅：http://caniuse.com/#feat=mediarecorder 截至2017年3月15日，浏览器兼容情况（不包括录音功能）是： PC版： Chrome 34+ Firefox 25+ Safari 6.0+ Opera 22+ Edge 完全兼容 IE （11及以下版本均不兼容） 移动版： iOS 6.0+ （须加 \"-webkit-\" 前缀） Android 5.0+ （4.4.4 及以下版本不兼容） Chrome for Android 34+ QQ浏览器 for Android 1.2+ UC浏览器 for Android （暂不兼容） 可见目前基本都比较完整地兼容大部分浏览器了。 接下来... 下一节《开始发出声音》，将立即播放一个mp3文件，并简要说明使用 Web Audio API 播放音频的步骤。 "},"chapter2.html":{"url":"chapter2.html","title":"2. 开始发出声音","keywords":"","body":"2. 开始发出声音 播放声音的基本步骤 AudioNode "},"chapter2-1.html":{"url":"chapter2-1.html","title":"2-1. 播放声音的基本步骤","keywords":"","body":"2-1. 播放声音的基本步骤 概念：AudioContext AudioContext 是一个管理、播放声音的对象，大概跟 Canvas 的 context 差不多。 我们可以在 AudioContext 里“画”出各种声音。 初始化 AudioContext var AudioContext = window.AudioContext || window.webkitAudioContext; var ctx = new AudioContext(); 加载、解码mp3文件 // 创建一个XMLHttpRequest请求对象 var request = new XMLHttpRequest(); // 请求一个MP3文件 request.open('GET', 'http://path/to/audio.mp3', true); // Web Audio API 固定为 \"arraybuffer\" request.responseType = 'arraybuffer'; // 加载完成后解码 request.onload = function() { ctx.decodeAudioData(request.response, function(buffer) { // 获得解码后的数据：buffer // 这里可以立即播放解码后的 buffer，也可以把 buffer 值先存起来 // 这个 playBuffer() 将在下文讲解如此实现 playBuffer(buffer); }, function (){ // 这里写解码出错的处理（例如文件损坏、格式不对等） }); }; // 发送这个XMLHttpRequest请求 request.send(); 使用 XMLHTTPRequest 对象加载mp3资源数据 加载完成后，mp3数据将被存储到 request.response 里 使用 ctx.decodeAudioData 把mp3解码成wav格式的 buffer（异步） 播放声音 function playBuffer(buffer) { var sourceNode = ctx.createBufferSource(); sourceNode.buffer = buffer; sourceNode.connect(ctx.destination); sourceNode.start(0); } 加载mp3并解码得到 buffer 之后… 创建 sourceNode 对象（下文将详解这个对象）； 把 buffer 传入 sourceNode.buffer 属性； 把 sourceNode 连接到 AudioContext 的音频输出口“.destination”； 对 sourceNode 执行 .start(0)，声音就出来了。 小结：播放声音的基本步骤 初始化 AudioContext 对象 使用 XMLHTTPRequest 对象从服务器获取mp3 把mp3数据用 ctx.decodeAudioData 转换成wav格式的 buffer 使用 SourceNode 对象（下文将详解这个对象）把 buffer 装起来 让 SourceNode 连接到音频输出口 destination 执行 .start(0) 触发 SourceNode 开始播放声音 "},"chapter2-2.html":{"url":"chapter2-2.html","title":"2-2. AudioNode","keywords":"","body":"2-2. AudioNode 概念：SourceNode SourceNode 是记录和输出波形声音的对象。 要使用 AudioContext 对象的 createBufferSource 方法创建，而不是 new。 var sourceNode = ctx.createBufferSource(); 它是其中一种 AudioNode（见下文）。 概念：AudioNode 这是一种由 AudioContext 生成的基本对象，用于生成或者处理音频波形数据。 AudioContext 提供很多特定的 AudioNode 可供使用，例如均衡器、滤波器、振荡器…… AudioNode 大体可分3类。 第一种：作为【声音源头】的 AudioNode，用于存储或生成声音（例如上文的 SourceNode）： 第二种：作为【过滤器】的 AudioNode，会对输入（In）的声音进行处理之后再输出（Out）。 （有些 AudioNode 可以有多个输入（In），然后对它们做混音后再输出。） 第三种：【destination】 是特殊的 AudioNode，它收到声音之后会直接传到耳机或扬声器，让我们最终听到声音。 把 AudioNode 连接起来… 多个 AudioNode 连接起来，可得到最终的声音： sourceNode.connect(node1); node1.connect(node2); node2.connect(node3); // ...... nodeN.connect(ctx.destination); 注意 一般来说，作为【声音源头】的 AudioNode （例如 SourceNode，以及将于进阶篇提及的 OscillatorNode），它的声音播放完毕后，它自身会立即销毁。 若需要再次播放，必须重新创建它。 例如，对于 SourceNode，每当重新播放同一个音频，每次都需要重新执行以下代码： function playBuffer(buffer) { var sourceNode = ctx.createBufferSource(); sourceNode.buffer = buffer; sourceNode.connect(ctx.destination); sourceNode.start(0); } "},"chapter2-3.html":{"url":"chapter2-3.html","title":"2-3. 总结","keywords":"","body":"2-3. 总结 播放声音的基本步骤： 初始化 AudioContext 对象 使用 XMLHTTPRequest 对象从服务器获取mp3 把mp3数据用 ctx.decodeAudioData 转换成wav格式的 buffer 使用 SourceNode 对象（下文将详解这个对象）把 buffer 装起来 让 SourceNode 连接到音频输出口 destination 执行 .start(0) 触发 SourceNode 开始播放声音 AudioNode 是 Web Audio Api 的基本类，由它派生的类可以处理音频。 AudioNode 派生的类可以分为3种： 作为【声音源头】的 AudioNode，用于存储或生成声音。 作为【过滤器】的 AudioNode，会对输入（In）的声音进行处理之后再输出（Out）。 【destination】 是特殊的 AudioNode，它收到声音之后会直接传到耳机或扬声器，让我们最终听到声音。 多个 AudioNode 用 .connect() 连接起来，可得到最终的声音。 接下来... 下一节《基本控制》，将对 SourceNode 做更多的控制，例如中途停止、循环播放、调节音量，并介绍如何实现多个 SourceNode 同时播放。 一个更好的选择 如果觉得 Web Audio API 写起来代码量太大，那么可以考虑使用我已经封装好的 Javascript 库 —— Benz Audio Engine。 项目 Github：https://github.com/BenzLeung/benz-audio-engine Benz Audio Engine 只把 Web Audio API 常用功能做个简单的封装，实现音效的加载、播放、暂停、音量调节。简单、干净，没有多余的功能。 参考文献 Web Audio API 简易入门教程，http://newhtml.net/web-audio-api%E7%AE%80%E6%98%93%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/ W3C Editor’s Draft，https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html "},"chapter3.html":{"url":"chapter3.html","title":"3. 基本控制","keywords":"","body":"3. 基本用法 本章对 SourceNode 做更多的控制，例如中途停止、循环播放、调节音量，并介绍如何实现多个 SourceNode 同时播放。 AudioNode 回顾 常用的 AudioNode 详解 SourceNode 更多用法 GainNode 音量调节器 AudioParam 数值调节器 DynamicsCompressorNode 动态压缩器 "},"chapter3-1.html":{"url":"chapter3-1.html","title":"3-1. AudioNode 回顾","keywords":"","body":"3-1. AudioNode 回顾 概念 AudioNode 是一种用于生成或处理音频数据的类。 AudioNode 是一个基础类，它有很多子类。 它的子类们，分别有不同的处理音频的功能 例如均衡器、音量增益、滤波器…… 种类 作为【声音源头】的 AudioNode。 用于存储波形数据，或者凭空生成波形数据。 音源没有输入，只有输出。 例： SourceNode ，用于存储波形数据并直接原样输出。 作为【过滤器】的 AudioNode。 用于过滤所输入的波形，并输出过滤后的结果。 过滤器至少接受1个输入，有1个输出。 有些过滤器可接受多个输入。 例：GainNode，用于调整音量。 作为【终点】的 destination。 这是Node的终点。 可接受多个输入（但不建议），无须输出。 输入到这里的声音将被用户听到。 代码 使用 .connect 方法把各种Node连接起来，起点是 SourceNode，终点是 destination： sourceNode.connect(node1); node1.connect(node2); node2.connect(node3); // ...... nodeN.connect(ctx.destination); 使用 context 创建 AudioNode 对象，而不是 new 一个。 例如使用 context.createBufferSource(); 而不是 new SourceNode(); var sourceNode = ctx.createBufferSource(); "},"chapter3-2.html":{"url":"chapter3-2.html","title":"3-2. 常用的 AudioNode 详解","keywords":"","body":"3-2. 常用的 AudioNode 详解 下面会详解3个最常用的 Node。 "},"chapter3-2-1.html":{"url":"chapter3-2-1.html","title":"3-2-1. SourceNode","keywords":"","body":"3-2-1. SourceNode 这是最常用的 Node ，用于存储波形数据。 创建方法： var sourceNode = ctx.createBufferSource(); 提供数据： sourceNode.buffer = buffer; 例： function playBuffer(buffer) { var sourceNode = ctx.createBufferSource(); sourceNode.buffer = buffer; sourceNode.connect(ctx.destination); sourceNode.start(0); } SourceNode.start() 开始播放 start(when, offset, duration) when: 何时开始播放（秒）（参数可省掉） offset: 音频的何处开始播放（秒）（参数可省掉） duration: 播放多长时间（参数可省掉） 返回值：无 例： sourceNode.start(ctx.currentTime + 5, 1.5, 3.0); 上述语句表示：5秒后开始播放（当前时间+5），从音频1.5秒开始，播放到4.5秒处停止（持续3.0秒）。 若 when 参数的值小于等于 ctx.currentTime ，则默认立即开始播放。下面 stop() 也一样。 SourceNode.stop() 结束 stop(when) when: 何时结束（秒）（参数可省掉） 返回值：无 例： sourceNode.stop(ctx.currentTime + 5); 上述语句表示：5秒后结束（当前时间+5），然后整个 SourceNode 就作废了（上一节讲过），要播放就需要重新创建对象。 SourceNode.loop / loopStart / loopEnd 循环播放设定 loop = [boolean] loopStart = [number] loopEnd = [number] loop: 是否循环播放 loopStart: 循环开始点 loopEnd: 循环结束点 例： sourceNode.loop = true; sourceNode.loopStart = 2.2; sourceNode.loopEnd = 6.0; 上述语句表示：2.2秒-6.0秒是循环节，播放到6.0秒处立即返回2.2秒继续播放。 可以指定循环节位置，是 SourceNode 比 HTML-5 的 更强大的地方之一。所以，在游戏开发中，即使背景音乐也应该用 Web Audio API 而不用 。 SourceNode.onended 播放完毕事件 onended = [function] onended: 播放完毕后触发的事件 例： sourceNode.onended = function () { alert('播放完毕！'); }; "},"chapter3-2-2.html":{"url":"chapter3-2-2.html","title":"3-2-2. GainNode 音量调节器","keywords":"","body":"3-2-2. GainNode 音量调节器 用于调节音量 创建方法： ctx.createGain() 调音量： gainNode.gain.value = 0.5（取值范围 0.0-1.0） 例：（把上文以及上一节的 playBuffer() 加上音量功能） function playBuffer(buffer, volume) { var sourceNode = ctx.createBufferSource(); sourceNode.buffer = buffer; var gainNode = ctx.createGain(); gainNode.gain.value = volume; sourceNode.connect(gainNode); gainNode.connect(ctx.destination); sourceNode.start(0); } 上述代码，Node 连接成 sourceNode -> gainNode -> destination。然后，可以随时通过修改 gainNode.gain.value 的值，来调节音量。 GainNode.gain gain = [AudioParam] 使用 gainNode.gain.value 调音量。 gain 是一个 AudioParam 对象，gain.value 才是音量的具体值（0.0-1.0）。 AudioParam 是个 Audio API 特有的对象（下文分解↓↓） "},"chapter3-2-3.html":{"url":"chapter3-2-3.html","title":"3-2-3. AudioParam 数值调节器","keywords":"","body":"3-2-3. AudioParam 数值调节器 AudioParam 不是 Node，而是一个很有用的类。 某些 Node 的数值型参数可采用 AudioParam 记录数值。 AudioParam 不仅可以直接给 value 一个固定值，而且能让数值产生渐变效果，例如让音量从高慢慢变低，产生淡出效果。 AudioParam.value value = [number] 直接改数值。 例： gainNode.gain.value = 0.5; AudioParam.setValueAtTime() setValueAtTime(value, startTime) 在指定时间把数值改成指定值。 value: 指定值。 startTime: 指定时间。 例： gainNode.gain.setValueAtTime(0.5, ctx.currentTime + 0); gainNode.gain.setValueAtTime(1.0, ctx.currentTime + 1); 上述代码将在0秒处设置关键帧，音量为0.5。然后在1秒处设置关键帧，音量为1.0。 音量与时间的关系如下图所示： AudioParam.linearRampToValueAtTime() 线性渐变 linearRampToValueAtTime(value, endTime) 把数值线性渐变到指定值 value: 指定值 endTime: 指定时间 例： gainNode.gain.setValueAtTime(0.5, ctx.currentTime + 0); gainNode.gain.linearRampToValueAtTime(1.0, ctx.currentTime + 1); 上述代码将在0秒处设置关键帧，音量为0.5。然后在1秒处设置线性渐变关键帧，音量为1.0。于是从上一关键帧到该关键帧，音量将产生线性渐变效果。 音量与时间的关系如下图所示： AudioParam.exponentialRampToValueAtTime() 指数渐变 exponentialRampToValueAtTime(value, endTime) 把数值指数渐变到指定值 value: 指定值 endTime: 指定时间 例： gainNode.gain.setValueAtTime(0.5, ctx.currentTime + 0); gainNode.gain.exponentialRampToValueAtTime(1.0, ctx.currentTime + 1); 上述代码将在0秒处设置关键帧，音量为0.5。然后在1秒处设置指数渐变关键帧，音量为1.0。于是从上一关键帧到该关键帧，音量将产生指数渐变效果。 音量与时间的关系图，（我画不出来 555~ 谁想办法帮画个？） AudioParam.setValueCurveAtTime() 平滑曲线 setValueCurveAtTime(values, startTime, duration) 在一段时间之内按照数组内的值一个个地平滑变化 values: (数组)指定值 startTime: 开始时间 duration: 持续时长 例： gainNode.gain.setValueCurveAtTime([0.0,0.2,0.5,0.1], ctx.currentTime + 0, 10); 上述代码将在10秒内，音量以 0.0→0.2→0.5→0.1 平滑过渡。 音量与时间的关系图，（我画不出来 555~ 谁想办法帮画个？） AudioParam 一个例子 var t0 = 0; var t1 = 0.1; var t2 = 0.2; var t3 = 0.3; var t4 = 0.4; var t5 = 0.6; var t6 = 0.7; var t7 = 1.0; var curveLength = 44100; var curve = new Float32Array(curveLength); for (var i = 0; i （本例来源：http://webaudio.github.io/web-audio-api/#audioparam-automation-example） "},"chapter3-2-4.html":{"url":"chapter3-2-4.html","title":"3-2-4. DynamicsCompressorNode 动态压缩器","keywords":"","body":"3-2-4. DynamicsCompressorNode 动态压缩器 这是一个动态混音器，用于把多个音源实时混音，并防止爆音。 创建方法：ctx.createDynamicsCompressor() 用法：直接把多个音源 connect 到这个Node即可。 例： var compressorNode = ctx.createDynamicsCompressor(); sourceNode1.connect(compressorNode); sourceNode2.connect(compressorNode); sourceNode3.connect(compressorNode); compressorNode.connect(ctx.destination); 虽然可以把多个 Node 直接 connect 到 ctx.destination，但是不建议这么做，因为这样可能会出现爆音现象。若有同时播放多个声音的需求（例如一个游戏的各种音效），记得通过 DynamicsCompressorNode 混合多个声音。 "},"chapter3-3.html":{"url":"chapter3-3.html","title":"3-3. 总结","keywords":"","body":"3-3. 总结 SourceNode 不仅可以播放一段音频，而且可以设置循环节，并且播放完毕后会触发 onended 事件。 GainNode 用来调节音量。 AudioParam 不是 AudioNode，它是一个非常有用的类，可以对音量或者其他数值类参数设置关键帧，产生渐变效果。 若有多个音频同时播放，它们都应该连接到 DynamicsCompressorNode 动态压缩器来处理混音，这样可以防止爆音。 接下来 下一节《一些声音常识》，在继续介绍 Web Audio API 的高级玩法之前，我觉得有必要先普及一些声音常识。因为有些高级玩法要求一些乐理知识。 所以，下一节没有代码。 一个更好的选择 如果觉得 Web Audio API 写起来代码量太大，那么可以考虑使用我已经封装好的 Javascript 库 —— Benz Audio Engine。 项目 Github：https://github.com/BenzLeung/benz-audio-engine 这个库仅仅使用了本节所提到的3个 Node 。简单、干净，没有多余的功能。 参考文献 Web Audio API W3C Working Draft "},"chapter4.html":{"url":"chapter4.html","title":"4. 一些声音常识","keywords":"","body":"4. 一些声音常识 在进一步学习更多玩法之前，有必要先科普一些声音常识。 音乐理论常识 声音物理学常识 声音的数字化常识 常见的音频格式 "},"chapter4-1.html":{"url":"chapter4-1.html","title":"4-1. 音乐理论常识","keywords":"","body":"4-1. 音乐理论常识 乐音与噪音 乐音：能明显分辨出音色、音高的声音，例如钢琴、小提琴、古筝等等。 噪音：混乱的，难以分辨音高的声音，例如锣、鼓、爆炸声、瀑布声等等。 乐音的三要素 音色：表示声音用什么乐器发声的，例如钢琴和小提琴的音色不一样。 响度：就是音量啦。 音高：跟我一起唱~ do re mi fa so la xi do ~~~ "},"chapter4-2.html":{"url":"chapter4-2.html","title":"4-2. 声音物理学常识","keywords":"","body":"4-1. 声音物理学常识 声波 上图就是声波的样子。 乐音的声波 音色 - 形状：声波的形状决定音色。 （左）三角波：嘟———— / （右）方形波：滴———— 响度 - 振幅：声波的振幅决定响度（音量）。 （左）音量较大 / （右）音量较小 音高 - 频率：声波的频率决定音高。 （左）低音： do ~~ / （右）高音： la ~~ "},"chapter4-3.html":{"url":"chapter4-3.html","title":"4-3. 声音的数字化常识","keywords":"","body":"4-1. 声音的数字化常识 声音的数字化采样 看图说话： 声波是一条连续的波形曲线，要把声波存储到硬盘里，就要把这条曲线转换成数字。 这个声波转换成数字的过程，称为数字化采样，简称采样。 上图是一段声波的第3.767秒到第3.768秒之间的采样。 就在这0.001秒，即1毫秒之间，采集了40+个点，把每个点的Y轴的对应值记录下来，然后把这一串数值按顺序存储到硬盘里，就变成了WAV格式的声音文件。 采样率 采样率就是1秒之内采样了多少个点，单位是 Hz 。 一般网上下载到的MP3音乐，其采样率一般是 44100 Hz。也就是说，1秒钟采样了 44100 个点。 看图说话： 文件格式: 44100Hz, 16 位, 立体声 这一行信息的意思是，每秒钟采样了44100个点，每个点占16位，16位就是2字节。 所以每秒钟需要占用空间 44100x2=88200 字节，就是大约 88 KB。 而由于这是立体声的，占两个声道，所以两个声道加起来，每秒钟就是大约 176 KB。 所以，如果这个声音文件是WAV格式的，那么它每秒钟占用大约 176 KB，一分钟就是 176x60=10560 KB。 比特率 比特率表示每秒钟占用多少硬盘空间，单位是 Kbps ，把这个单位展开成英文就是“Kbit per second”，中文意思是“千比特每秒”。 例如，128 Kbps 意思是每秒占用空间 128 Kbit。 1个bit就是二进制数字中的1位，所以 8bit=1字节 。 所以，128 Kbit 就是 16 KB （128 / 8 = 16）。 所以，128 Kbps 就是 16 KB/s ，即每秒占 16 KB。 每秒 16 KB，那么每分钟就是 960 KB 。所以，如果是 128 Kbps 的 MP3，一首3分钟的歌曲大约占用不到 3 MB 左右。 如果使用不压缩的 WAV 格式，根据上文所述，那么“44100Hz, 16 位, 立体声”的WAV文件就是 176 KB/s ，即比特率就是 1408 Kbps。 比特率是用来衡量声音文件的压缩率的。比特率越小，文件越小，压缩率越高。 对于同一种声音文件格式，比特率越小代表音质越差。但要是文件格式不一样，比特率就不能用来对比音质了。 "},"chapter4-4.html":{"url":"chapter4-4.html","title":"4-4. 常见的音频格式","keywords":"","body":"4-4. 常见的音频格式 MP3 一种很常见的声音文件格式，比特率范围是 30 - 320 Kbps。 网上最流行 128 Kbps。 现在 MP3 已经被所有浏览器所支持了。（Can I Use: MP3） WAV 另一种很常见的声音文件格式，音频数据不经过任何处理和压缩，一个一个字节地忠实地记录每一个采样数据，因此文件体积比较大，不便于网络传播。 但是在 Web Audio API 中，有个 AudioNode 称为 Convolver （后文会介绍）的，必须用到一些特殊的 WAV 格式音频。 WMA 在2000年-2010年之间还蛮常见的一种声音格式，由微软公司发明。 当时被很多 MP3 随身听支持，压缩率比 MP3 高。即 WMA 的 64 Kbps 的音质大概相当于 MP3 128 Kbps（维基百科：WMA）。 但是可能由于微软开出版权费过高（我猜的），所以现在的浏览器全都不支持了。 AAC 一种网上不太常见但是兼容性最接近 MP3 的声音文件格式。常见扩展名有 .aac .mp4 .m4a .3gp。 这是 MP3 的继承者，都是 MPEG 系列的标准，因此一般来说只要支持 MP3 的浏览器都能支持 AAC。 AAC 的压缩率几乎肯定比 MP3 高，但是能高多少取决于压缩软件是否给力，因为根据维基百科的描述，AAC是个庞大家族，有很多种AAC，压缩率参差不齐。 不过无论如何，在Web端，AAC 确实是一种比 MP3 更省网络流量的选择。 现在 AAC 也已经被所有浏览器所支持了（Can I Use: AAC），所以以后都不需要用 MP3 了，放心地用 AAC 吧。 "},"chapter4-5.html":{"url":"chapter4-5.html","title":"4-5. 总结","keywords":"","body":"4-5. 总结 音乐理论常识 乐音：能明显分辨出音色、音高的声音 噪音：混乱的，难以分辨音高的声音 乐音的三要素：音色、响度、音高 声音物理学常识 声波的形状决定音色。 声波的振幅决定响度（音量）。 声波的频率决定音高。 声波转换成计算机数字的过程，称为数字化采样。 采样率就是1秒之内采样了多少个点，单位是 Hz 。 比特率表示每秒钟占用多少硬盘空间，单位是 Kbps。 常见的音频格式：MP3、WAV、WMA、AAC WMA 已经没什么浏览器支持了。 MP3 是兼容性最好的格式。 WAV 体积大，不便于网络传输，但仍然有些场景需要用到它。 AAC 的兼容性已经赶上 MP3，而且 AAC 压缩率比 MP3 要高。所以一般情况下，强烈建议使用 AAC 格式！ 接下来... 下一节《进阶》，介绍 Web Audio API 的更多玩法，每种玩法都有我自制的Demo。 "},"chapter5.html":{"url":"chapter5.html","title":"5. 进阶","keywords":"","body":"5. 进阶 这一节主要列出一些 API ，这些 API 或者是我觉得比较好玩的，或者是我觉得在做音乐播放器或者游戏时有很大可能用得着的。 Web Audio API 中每个 API 可能有很多专业的高级属性和方法，有些（我认为）比较难用到的这里就省略了。 这里列出的 API 都有我自制的 Demo，纯手工制作，如有雷同，纯属巧合。 【全部 Demo 的目录】 DynamicsCompressor - 动态混音 Panner - 3D立体环绕音效 BiquadFilter - 滤波器、均衡器 Analyser - 频谱分析器（频谱图、时域图） Convolver - 卷积运算处理（环境混响音效） Oscillator - 振荡器（声波生成器） "},"chapter5-1.html":{"url":"chapter5-1.html","title":"5-1. DynamicsCompressor - 动态混音","keywords":"","body":"5-1. DynamicsCompressor - 动态混音 【Demo】 用于把多个音源实时混音，并防止爆音。 对象创建方法：ctx.createDynamicsCompressor() 用法：直接把多个音源 connect 到这个Node即可。 虽然可以把多个 Node 直接 connect 到 ctx.destination，但是不建议这么做，因为这样可能会出现爆音现象。若有同时播放多个声音的需求（例如一个游戏的各种音效），记得通过 DynamicsCompressorNode 混合多个声音。 "},"chapter5-2.html":{"url":"chapter5-2.html","title":"5-2. Panner - 3D立体环绕音效","keywords":"","body":"5-2. Panner - 3D立体环绕音效 【Demo】 把声音的声源移动到3D空间中指定的点 (x, y, z)，模拟3D空间音效。 可以在声音播放期间实时调整空间坐标值 (x, y, z)，让声音绕着你转圈圈。 对象创建方法：ctx.createPanner() 常用属性方法： PannerNode.setPosition(x, y, z) 设置声源空间位置 (x, y, z)。(x, y, z)是代表位置的坐标值。 PannerNode.setOrientation(x, y, z) 设置声源的朝向 (x, y, z)。(x, y, z)是代表方向的向量值。一个人背对你说话和正对你说话，效果是不一样的。 PannerNode.setVelocity(x, y, z) 设置声源的运动方向和速度 (x, y, z)。(x, y, z)是代表方向和速度的向量值。一个人站着说话和一边跑步一边说话，效果也是不一样的。 "},"chapter5-3.html":{"url":"chapter5-3.html","title":"5-3. BiquadFilter - 滤波器、均衡器","keywords":"","body":"5-3. BiquadFilter - 滤波器、均衡器 【Demo】 过滤或增益指定频率的声波。 对象创建方法：ctx.createBiquadFilter() 常用属性方法： BiquadFilterNode.type 指定滤波器类型（详见下表） BiquadFilterNode.frequency 指定一个频率（详见下表） BiquadFilterNode.Q 设定容许度（详见下表） BiquadFilterNode.gain 设定增益值（详见下表） type 用途 frequency Q gain lowpass 低通滤波，只允许低频声音通过。 能通过的频率值界线（Hz），例如440，即只让 0-440Hz 的声音通过，削减掉 440-99999Hz 的声音。 削减度，数值越小则声音削减越厉害。 不可用。 highpass 高通滤波，只允许高频声音通过。 能通过的频率值界线（Hz），例如440，即只让 440-99999Hz 的声音通过，削减掉 0-440Hz 的声音。 削减度，数值越小则声音削减越厉害。 不可用。 peaking 峰值滤波，增益或削减某一频率的声音 要增益或削减的频率值中间点（Hz）。 范围，例如频率 440Hz，范围Q是20，那么范围就是 430-450Hz。 增益或削减度，正值增益，负值削减。 bandpass, lowshelf, highshelf, notch, allpass 带通滤波, 低架滤波, 高架滤波, 陷波器, 全通滤波 不常用，略 不常用，略 不常用，略 "},"chapter5-4.html":{"url":"chapter5-4.html","title":"5-4. Analyser - 频谱分析器（频谱图、时域图）","keywords":"","body":"5-4. Analyser - 频谱分析器（频谱图、时域图） 【Demo 1，频谱图】 【Demo 2，时域图】 获得音频的频谱数据，可用于绘制频谱图（条状的）和时域图（线状的）。 它不会改变声音波形，只读取波形数据。也就是说，输入和输出的声波是完全一样的，输入什么就输出什么。 对象创建方法：ctx.createAnalyser() 常用属性方法： Analyser.fftSize 频谱分析下的快速傅里叶变换的大小（难理解？没事，看下一个属性就好），取值范围是 32-2048 之内 2 的整数次方，即 32、64、128、256、512、1024、2048。默认值为 2048。 Analyser.frequencyBinCount fftSize 值的一半。这个值代表你要绘制的条形频谱图中有多少条条形。注意，这是个只读的属性，要修改这个属性的值请改 fftSize。 Analyser.smoothingTimeConstant 让频谱图的动画带有平滑过渡效果，取值范围 0.0-1.0，0.0 代表不平滑，1.0 代表很平滑。 Analyser.getByteFrequencyData(array) 把当前的即时频谱图数据复制到 array 数组里。array 数组须事先创建好，Uint8Array 类型，数组大小为 frequencyBinCount，即应该事先有以下这一代码： var array = new Uint8Array(analyser.frequencyBinCount); Analyser.getByteTimeDomainData(array) 把当前的即时时域图数据复制到 array 数组里。array 数组须事先创建好，Uint8Array 类型，数组大小为 frequencyBinCount，即应该事先有以下这一代码： var array = new Uint8Array(analyser.frequencyBinCount); "},"chapter5-5.html":{"url":"chapter5-5.html","title":"5-5. Convolver - 卷积运算处理（环境混响音效）","keywords":"","body":"5-5. Convolver - 卷积运算处理（环境混响音效） 【Demo】 对音频进行卷积运算，用于添加环境音效，例如房间、音乐厅、剧院、电话等等。 在声学中，回声可以表示为声波与“特定波形”的卷积。 这些“特定波形”可以反映房间回声、教堂回声、电话声等等，并且可以用WAV格式存储。 参考：维基百科：卷积 （其实卷积到底是什么鬼，我也不太明白，维基百科的解释我看得似懂非懂、不明觉厉。） （总之不管卷积了，能实现环境混响音效就好 ^_^） 对象创建方法：ctx.createConvolver() 常用属性方法： ConvolverNode.buffer 把需要做卷积运算的波形数据扔进这个属性，就像 SourceNode.buffer 一样个扔法。然后输入的声波将会与这个 buffer 数据进行卷积运算后输出。 注1： 用于卷积运算的特定波形必须使用无损格式存储。也就是说可以是WAV格式的，但不能是MP3、AAC等有损压缩格式。 注2： 可以在这儿找到想要的卷积波形WAV文件—— 包括大量卷积文件的 Github 这大量卷积文件的 Demo "},"chapter5-6.html":{"url":"chapter5-6.html","title":"5-6. Oscillator - 振荡器（声波生成器）","keywords":"","body":"5-6. Oscillator - 振荡器（声波生成器） 【Demo 1，简易电子琴】 【Demo 2，铃儿响叮当】 【Demo 3，各种波形对比】 发出指定频率和指定形状的声波。 这是一种作为音源的 Node，没有输入（即其他Node不能connect它）。 对象创建方法：ctx.createOscillator() 常用属性方法： OscillatorNode.type 指定声波类型，有五种值：方形波square、三角波triangle、正弦波sine、锯齿波sawtooth、自定义custom。 OscillatorNode.frequency 指定一个频率 注1： 使用振荡器可以实现零流量演奏音乐，但是需要一定的乐理知识。 注2： 一般来说，方形波和锯齿波用于演奏高音和中音，三角波和正弦波用于演奏低音。 注3： 可以在维基百科找到音高和频率的对照表，把每个音符所对应的频率赋值给 OscillatorNode.frequency 即可演奏音乐—— 维基百科：音高频率表 "},"chapter5-7.html":{"url":"chapter5-7.html","title":"5-7. 总结","keywords":"","body":"5-7. 总结 DynamicsCompressor - 动态混音 Panner - 3D立体环绕音效 BiquadFilter - 滤波器、均衡器 Analyser - 频谱分析器（频谱图、时域图） Convolver - 卷积运算处理（环境混响音效） Oscillator - 振荡器（声波生成器） 以上所有 Node 都有自制的 Demo 本节的内容都用不着？ 那么可以考虑使用我已经封装好的 Javascript 库 —— Benz Audio Engine。 项目 Github：https://github.com/BenzLeung/benz-audio-engine 这个库仅仅用到了本节所提到的第一个 API —— DynamicsCompressor，以及 SourceNode 和 GainNode（可能后续会考虑加入 Panner）。简单、干净，没有多余的功能。 "},"chapter6.html":{"url":"chapter6.html","title":"完结了。","keywords":"","body":"6. 完结了。 这个小教程就先写到这里为止了，然而 Web Audio API 的内容并不止于此。 还有一些更加高级的 API，我觉得咱们平民大众应该这辈子都用不着的了。那些这里没有提及的 API 估计是用来把 Adobe Audition 移植成网页版的吧。 （注：Adobe Audition 一个著名的音频处理软件，很强大的。） 好了，如果写得不好，欢迎提建议。 我的Github：https://github.com/benzleung/ 我的Blog：https://benzleung.github.io/ "}}